{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e074e679-2ea9-4a07-9bfe-63feaec984c4",
   "metadata": {},
   "source": [
    "## DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87914705-79bd-477e-a232-0383a021adb3",
   "metadata": {},
   "source": [
    "A decision tree is a type of machine learning algorithm used for classification and regression tasks. It consists of a tree-like structure where each internal node represents a feature or attribute, each branch represents a decision based on that feature, and each leaf node represents a predicted output.\n",
    "\n",
    "To train a decision tree, the algorithm uses a dataset with labeled examples to create the tree structure. It starts with the root node, which includes all the examples, and selects the feature that provides the most information gain to split the data into two subsets. It then repeats this process for each subset until it reaches a stopping criterion, such as a maximum tree depth or minimum number of examples in a leaf node.\n",
    "\n",
    "Once the decision tree is trained, it can be used to predict the output for new, unseen examples. To make a prediction, the algorithm starts at the root node and follows the branches based on the values of the input features until it reaches a leaf node. The predicted output for that example is the value associated with the leaf node.\n",
    "\n",
    "Decision trees have several advantages, such as being easy to interpret and visualize, handling both numerical and categorical data, and handling missing values. However, they can also suffer from overfitting if the tree is too complex or if there is noise or outliers in the data.\n",
    "\n",
    "To address this issue, various techniques such as pruning, ensemble methods, and regularization can be used to simplify the decision tree or combine multiple trees to improve generalization performance. Additionally, decision trees may not perform well with highly imbalanced datasets or datasets with many irrelevant features, and they may not be suitable for tasks where the relationships between features and outputs are highly nonlinear or complex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a08f1fd4-79f1-4b3c-af67-d15075b7bafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbf320b4-1268-4cb8-a8b2-a39455da1b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "    def __init__(self, max_depth=None, min_sample_split=2):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_sample_split = min_sample_split\n",
    "        self.tree = None\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.tree = self._build_tree(X, y)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        return np.array([self._predict_single(x, self.tree) for x in X])\n",
    "    \n",
    "    def _gini(self, y):\n",
    "        # measures \"purity\" or \"impurity\" of a split gini = 0 : pure (all samples of the same class)\n",
    "        classes, counts = np.unique(y, return_counts=True)\n",
    "        return 1.0 - sum((count / len(y)) ** 2 for count in counts)\n",
    "    \n",
    "    \n",
    "    def _build_tree(self, X, y, depth=0):\n",
    "        # builds the tree recursively\n",
    "        # structure of the tree is created based on the \"best splits\"\n",
    "        num_samples, num_features = X.shape\n",
    "        num_labels = len(np.unique(y))\n",
    "        \n",
    "        if depth >= self.max_depth or num_labels == 1 or num_samples <= self.min_sample_split:\n",
    "            leaf_label = np.bincount(y).argmax()\n",
    "            return {'type': 'leaf', 'class': leaf_label}\n",
    "        \n",
    "        feature_index, threshold = self._best_split(X, y)\n",
    "        \n",
    "        if feature_index is None:\n",
    "            leaf_label = np.bincount(y).argmax()\n",
    "            return {'type' : 'leaf', 'class' : leaf_label}\n",
    "        \n",
    "        left_mask = X[: , feature_index] <= threshold\n",
    "        right_mask = X[: , feature_index] > threshold\n",
    "        \n",
    "        left_subtree = self._build_tree(X[left_mask], y[left_mask], depth + 1)\n",
    "        right_subtree = self._build_tree(X[right_mask], y[right_mask], depth + 1)\n",
    "        \n",
    "        return {\n",
    "            'type' : 'node',\n",
    "            'feature_index' : feature_index,\n",
    "            'threshold' : threshold,\n",
    "            'left' : left_subtree,\n",
    "            'right' : right_subtree\n",
    "        }\n",
    "    \n",
    "    def _best_split(self, X, y):\n",
    "        \"\"\"\n",
    "        evaluates all possible feature/threshold combinations and selects the one that results in the most “pure” child nodes\n",
    "        \"\"\"\n",
    "        best_gini = float(\"inf\")\n",
    "        best_index, best_value = None, None\n",
    "        n_samples, n_features = X.shape\n",
    "        \n",
    "        for feature_index in range(n_features):\n",
    "            thresholds = X[: , feature_index]\n",
    "            for threshold in thresholds:\n",
    "                left_mask = X[:, feature_index] <= threshold\n",
    "                right_mask = X[: , feature_index] > threshold\n",
    "                \n",
    "                y_left, y_right = y[left_mask], y[right_mask]\n",
    "                \n",
    "                if len(y_left) == 0 or len(y_right) == 0:\n",
    "                    continue\n",
    "                    \n",
    "                left_gini, right_gini = self._gini(y_left), self._gini(y_right)\n",
    "                \n",
    "                weighted_gini = (left_gini * len(y_left) + right_gini * len(y_right)) / len(y)\n",
    "                \n",
    "                if weighted_gini < best_gini:\n",
    "                    best_gini = weighted_gini\n",
    "                    best_index = feature_index\n",
    "                    best_value = threshold\n",
    "                    \n",
    "        return best_index, best_value\n",
    "    \n",
    "    def _predict_single(self, x, tree):\n",
    "        if tree['type'] == 'leaf':\n",
    "            return tree['class']\n",
    "        feature_value = x[tree['feature_index']]\n",
    "        if feature_value <= tree['threshold']:\n",
    "            return self._predict_single(x, tree['left'])\n",
    "        else:\n",
    "            return self._predict_single(x, tree['right'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42c05856-3ac1-42cc-a692-5f99eee356ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom Decision Tree Accuracy on Iris: 0.9555555555555556\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "tree = DecisionTree(max_depth=5)\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "y_pred = tree.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Custom Decision Tree Accuracy on Iris:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c4e97f-f152-403e-946b-d8a00073e2a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37a2de2-208e-4b62-aa9a-fd22df12395f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
